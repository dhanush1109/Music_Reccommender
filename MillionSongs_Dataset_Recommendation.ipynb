{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (1.21.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dhanu\\appdata\\roaming\\python\\python37\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhanu\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 23.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class popularity_recommender_py():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        self.popularity_recommendations = None\n",
    "        \n",
    "    #Create the popularity based recommender system model\n",
    "    def create(self, train_data, user_id, item_id):\n",
    "        self.train_data = train_data\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "\n",
    "        #Get a count of user_ids for each unique song as recommendation score\n",
    "        train_data_grouped = train_data.groupby([self.item_id]).agg({self.user_id: 'count'}).reset_index()\n",
    "        train_data_grouped.rename(columns = {'user_id': 'score'},inplace=True)\n",
    "    \n",
    "        #Sort the songs based upon recommendation score\n",
    "        train_data_sort = train_data_grouped.sort_values(['score', self.item_id], ascending = [0,1])\n",
    "    \n",
    "        #Generate a recommendation rank based upon score\n",
    "        train_data_sort['Rank'] = train_data_sort['score'].rank(ascending=0, method='first')\n",
    "        \n",
    "        #Get the top 10 recommendations\n",
    "        self.popularity_recommendations = train_data_sort.head(10)\n",
    "\n",
    "    #Use the popularity based recommender system model to\n",
    "    #make recommendations\n",
    "    def recommend(self, user_id):    \n",
    "        user_recommendations = self.popularity_recommendations\n",
    "        \n",
    "        #Add user_id column for which the recommendations are being generated\n",
    "        user_recommendations['user_id'] = user_id\n",
    "    \n",
    "        #Bring user_id column to the front\n",
    "        cols = user_recommendations.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        user_recommendations = user_recommendations[cols]\n",
    "        \n",
    "        return user_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for Item similarity based Recommender System model\n",
    "class item_similarity_recommender_py():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        self.cooccurence_matrix = None\n",
    "        self.songs_dict = None\n",
    "        self.rev_songs_dict = None\n",
    "        self.item_similarity_recommendations = None\n",
    "        \n",
    "    #Get unique items (songs) corresponding to a given user\n",
    "    def get_user_items(self, user):\n",
    "        user_data = self.train_data[self.train_data[self.user_id] == user]\n",
    "        user_items = list(user_data[self.item_id].unique())\n",
    "        \n",
    "        return user_items\n",
    "        \n",
    "    #Get unique users for a given item (song)\n",
    "    def get_item_users(self, item):\n",
    "        item_data = self.train_data[self.train_data[self.item_id] == item]\n",
    "        item_users = set(item_data[self.user_id].unique())\n",
    "            \n",
    "        return item_users\n",
    "        \n",
    "    #Get unique items (songs) in the training data\n",
    "    def get_all_items_train_data(self):\n",
    "        all_items = list(self.train_data[self.item_id].unique())\n",
    "            \n",
    "        return all_items\n",
    "        \n",
    "    #Construct cooccurence matrix\n",
    "    def construct_cooccurence_matrix(self, user_songs, all_songs):\n",
    "            \n",
    "        ####################################\n",
    "        #Get users for all songs in user_songs.\n",
    "        ####################################\n",
    "        user_songs_users = []        \n",
    "        for i in range(0, len(user_songs)):\n",
    "            user_songs_users.append(self.get_item_users(user_songs[i]))\n",
    "            \n",
    "        ###############################################\n",
    "        #Initialize the item cooccurence matrix of size \n",
    "        #len(user_songs) X len(songs)\n",
    "        ###############################################\n",
    "        cooccurence_matrix = np.matrix(np.zeros(shape=(len(user_songs), len(all_songs))), float)\n",
    "           \n",
    "        #############################################################\n",
    "        #Calculate similarity between user songs and all unique songs\n",
    "        #in the training data\n",
    "        #############################################################\n",
    "        for i in range(0,len(all_songs)):\n",
    "            #Calculate unique listeners (users) of song (item) i\n",
    "            songs_i_data = self.train_data[self.train_data[self.item_id] == all_songs[i]]\n",
    "            users_i = set(songs_i_data[self.user_id].unique())\n",
    "            \n",
    "            for j in range(0,len(user_songs)):       \n",
    "                    \n",
    "                #Get unique listeners (users) of song (item) j\n",
    "                users_j = user_songs_users[j]\n",
    "                    \n",
    "                #Calculate intersection of listeners of songs i and j\n",
    "                users_intersection = users_i.intersection(users_j)\n",
    "                \n",
    "                #Calculate cooccurence_matrix[i,j] as Jaccard Index\n",
    "                if len(users_intersection) != 0:\n",
    "                    #Calculate union of listeners of songs i and j\n",
    "                    users_union = users_i.union(users_j)\n",
    "                    \n",
    "                    cooccurence_matrix[j,i] = float(len(users_intersection))/float(len(users_union))\n",
    "                else:\n",
    "                    cooccurence_matrix[j,i] = 0\n",
    "                    \n",
    "        \n",
    "        return cooccurence_matrix\n",
    "\n",
    "    \n",
    "    #Use the cooccurence matrix to make top recommendations\n",
    "    def generate_top_recommendations(self, user, cooccurence_matrix, all_songs, user_songs):\n",
    "        print(\"Non zero values in cooccurence_matrix :%d\" % np.count_nonzero(cooccurence_matrix))\n",
    "        \n",
    "        #Calculate a weighted average of the scores in cooccurence matrix for all user songs.\n",
    "        user_sim_scores = cooccurence_matrix.sum(axis=0)/float(cooccurence_matrix.shape[0])\n",
    "        user_sim_scores = np.array(user_sim_scores)[0].tolist()\n",
    " \n",
    "        #Sort the indices of user_sim_scores based upon their value\n",
    "        #Also maintain the corresponding score\n",
    "        sort_index = sorted(((e,i) for i,e in enumerate(list(user_sim_scores))), reverse=True)\n",
    "    \n",
    "        #Create a dataframe from the following\n",
    "        columns = ['user_id', 'song', 'score', 'rank']\n",
    "        #index = np.arange(1) # array of numbers for the number of samples\n",
    "        df = pandas.DataFrame(columns=columns)\n",
    "         \n",
    "        #Fill the dataframe with top 10 item based recommendations\n",
    "        rank = 1 \n",
    "        for i in range(0,len(sort_index)):\n",
    "            if ~np.isnan(sort_index[i][0]) and all_songs[sort_index[i][1]] not in user_songs and rank <= 10:\n",
    "                df.loc[len(df)]=[user,all_songs[sort_index[i][1]],sort_index[i][0],rank]\n",
    "                rank = rank+1\n",
    "        \n",
    "        #Handle the case where there are no recommendations\n",
    "        if df.shape[0] == 0:\n",
    "            print(\"The current user has no songs for training the item similarity based recommendation model.\")\n",
    "            return -1\n",
    "        else:\n",
    "            return df\n",
    " \n",
    "    #Create the item similarity based recommender system model\n",
    "    def create(self, train_data, user_id, item_id):\n",
    "        self.train_data = train_data\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "\n",
    "    #Use the item similarity based recommender system model to\n",
    "    #make recommendations\n",
    "    def recommend(self, user):\n",
    "        \n",
    "        ########################################\n",
    "        #A. Get all unique songs for this user\n",
    "        ########################################\n",
    "        user_songs = self.get_user_items(user)    \n",
    "            \n",
    "        print(\"No. of unique songs for the user: %d\" % len(user_songs))\n",
    "        \n",
    "        ######################################################\n",
    "        #B. Get all unique items (songs) in the training data\n",
    "        ######################################################\n",
    "        all_songs = self.get_all_items_train_data()\n",
    "        \n",
    "        print(\"no. of unique songs in the training set: %d\" % len(all_songs))\n",
    "         \n",
    "        ###############################################\n",
    "        #C. Construct item cooccurence matrix of size \n",
    "        #len(user_songs) X len(songs)\n",
    "        ###############################################\n",
    "        cooccurence_matrix = self.construct_cooccurence_matrix(user_songs, all_songs)\n",
    "        \n",
    "        #######################################################\n",
    "        #D. Use the cooccurence matrix to make recommendations\n",
    "        #######################################################\n",
    "        df_recommendations = self.generate_top_recommendations(user, cooccurence_matrix, all_songs, user_songs)\n",
    "                \n",
    "        return df_recommendations\n",
    "    \n",
    "    #Get similar items to given items\n",
    "    def get_similar_items(self, item_list):\n",
    "        \n",
    "        user_songs = item_list\n",
    "        \n",
    "        ######################################################\n",
    "        #B. Get all unique items (songs) in the training data\n",
    "        ######################################################\n",
    "        all_songs = self.get_all_items_train_data()\n",
    "        \n",
    "        print(\"no. of unique songs in the training set: %d\" % len(all_songs))\n",
    "         \n",
    "        ###############################################\n",
    "        #C. Construct item cooccurence matrix of size \n",
    "        #len(user_songs) X len(songs)\n",
    "        ###############################################\n",
    "        cooccurence_matrix = self.construct_cooccurence_matrix(user_songs, all_songs)\n",
    "        \n",
    "        #######################################################\n",
    "        #D. Use the cooccurence matrix to make recommendations\n",
    "        #######################################################\n",
    "        user = \"\"\n",
    "        df_recommendations = self.generate_top_recommendations(user, cooccurence_matrix, all_songs, user_songs)\n",
    "         \n",
    "        return df_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting recommenders\n",
      "  Using cached https://files.pythonhosted.org/packages/72/a0/eac6de0224c5d6608d71146fc4ce1aa3931aaecf9b111b7586972580349e/recommenders-1.1.1-py3-none-any.whl\n",
      "Collecting bottleneck<2,>=1.2.1 (from recommenders)\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/ad/5992d5623300e3bd1712faac694d2a37f8f21ddb74681b6d9c64938dc14c/Bottleneck-1.3.7-cp37-cp37m-win32.whl\n",
      "Collecting seaborn<1,>=0.8.1 (from recommenders)\n",
      "  Using cached https://files.pythonhosted.org/packages/8f/2e/17bbb83fbf102687bb2aa3d808add39da820a7698159302a1a69bb82e01c/seaborn-0.12.2-py3-none-any.whl\n",
      "Collecting requests<3,>=2.0.0 (from recommenders)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting lightfm<2,>=1.15 (from recommenders)\n",
      "  Using cached https://files.pythonhosted.org/packages/1f/96/5ec230f5c27811534af0faaa8525f11c1000ee1c24c8a82c0546d0724aea/lightfm-1.17.tar.gz\n",
      "Collecting pyyaml<6,>=5.4.1 (from recommenders)\n",
      "  Using cached https://files.pythonhosted.org/packages/76/24/8f40555a59ab5cd5024264b395642a998056ab520fcaa2d6589e1a5190d9/PyYAML-5.4.1-cp37-cp37m-win32.whl\n",
      "Collecting lightgbm>=2.2.1 (from recommenders)\n",
      "  Using cached https://files.pythonhosted.org/packages/98/a9/01f50aee85949ba713733b69a3f0b42d39719a414a0e29bdf2a9f05ecc53/lightgbm-4.1.0.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_internal\\basecommand.py\", line 228, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 291, in run\n",
      "    resolver.resolve(requirement_set)\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 103, in resolve\n",
      "    self._resolve_one(requirement_set, req)\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 257, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 210, in _get_abstract_dist_for\n",
      "    self.require_hashes\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 324, in prepare_linked_requirement\n",
      "    abstract_dist.prep_for_dist(finder, self.build_isolation)\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 126, in prep_for_dist\n",
      "    build_requirements, isolate = self.req.get_pep_518_info()\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_internal\\req\\req_install.py\", line 448, in get_pep_518_info\n",
      "    pp_toml = pytoml.load(f)\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_vendor\\pytoml\\parser.py\", line 10, in load\n",
      "    return loads(fin.read(), translate=translate, filename=getattr(fin, 'name', repr(fin)))\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_vendor\\pytoml\\parser.py\", line 23, in loads\n",
      "    ast = _p_toml(src)\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_vendor\\pytoml\\parser.py\", line 352, in _p_toml\n",
      "    s.expect_eof()\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_vendor\\pytoml\\parser.py\", line 124, in expect_eof\n",
      "    return self._expect(self.consume_eof())\n",
      "  File \"c:\\users\\dhanu\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pip\\_vendor\\pytoml\\parser.py\", line 164, in _expect\n",
      "    raise TomlError('msg', self._pos[0], self._pos[1], self._filename)\n",
      "pip._vendor.pytoml.core.TomlError: C:\\Users\\dhanu\\AppData\\Local\\Temp\\pip-install-aj2ybl63\\lightgbm\\pyproject.toml(62, 1): msg\n",
      "You are using pip version 10.0.1, however version 23.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Recommenders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19484\\1001742002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mRecommenders\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRecommenders\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Recommenders'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "import Recommenders as Recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read user_id, song_id, listen_count \n",
    "#This step might take time to download data from external sources\n",
    "\n",
    "\n",
    "song_df_a = pandas.read_csv('triplets_file.csv')\n",
    "song_df_a.columns = ['user_id', 'song_id', 'listen_count']\n",
    "\n",
    "#Read song  metadata\n",
    "song_df_b =  pandas.read_csv('song_data.csv')\n",
    "\n",
    "#Merge the two dataframes above to create input dataframe for recommender systems\n",
    "song_df1 = pandas.merge(song_df_a, song_df_b.drop_duplicates(['song_id']), on=\"song_id\", how=\"left\")\n",
    "song_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total no of songs:\",len(song_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df1 = song_df1.head(100000)\n",
    "\n",
    "#Merge song title and artist_name columns to make a new column\n",
    "song_df1['song'] = song_df1['title'].map(str) + \" - \" + song_df1['artist_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_gr = song_df1.groupby(['song']).agg({'listen_count': 'count'}).reset_index()\n",
    "grouped_sum = song_gr['listen_count'].sum()\n",
    "song_gr['percentage']  = song_gr['listen_count'].div(grouped_sum)*100\n",
    "song_gr.sort_values(['listen_count', 'song'], ascending = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = song_df1['user_id'].unique()\n",
    "print(\"The no. of unique users:\", len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_data = train_test_split(song_df1, test_size = 0.20, random_state=0)\n",
    "print(train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = Recommenders.popularity_recommender_py()                               #create an instance of the class\n",
    "pm.create(train, 'user_id', 'song')\n",
    "\n",
    "user_id1 = u[5]                                                          #Recommended songs list for a user\n",
    "pm.recommend(user_id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2 = u[8]\n",
    "pm.recommend(user_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_model = Recommenders.item_similarity_recommender_py()\n",
    "is_model.create(train, 'user_id', 'song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the songs for the user\n",
    "user_id1 = u[5]\n",
    "user_items1 = is_model.get_user_items(user_id1)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Songs played by first user %s:\" % user_id1)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "\n",
    "for user_item in user_items1:\n",
    "    print(user_item)\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Similar songs recommended for the first user:\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "#Recommend songs for the user using personalized model\n",
    "is_model.recommend(user_id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2 = u[7]\n",
    "#Fill in the code here\n",
    "user_items2 = is_model.get_user_items(user_id2)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Songs played by second user %s:\" % user_id2)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "\n",
    "for user_item in user_items2:\n",
    "    print(user_item)\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Similar songs recommended for the second user:\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "#Recommend songs for the user using personalized model\n",
    "is_model.recommend(user_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user(user__id):\n",
    "    user_ids = u[user__id]\n",
    "#Fill in the code here\n",
    "    user_itemss = is_model.get_user_items(user_ids)\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "    print(\"Songs played by  user %s:\" % user_ids)\n",
    "    print(\"------------------------------------------------------------------------------------\")\n",
    "\n",
    "    for user_item in user_itemss:\n",
    "        print(user_item)\n",
    "\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(\"Similar songs recommended for the  user:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "#Recommend songs for the user using personalized model\n",
    "    is_model.recommend(user_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
